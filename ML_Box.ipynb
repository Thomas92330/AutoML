{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : high_diamond_ranked_10min.csv1.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.3347346782684326 seconds\n",
      "\n",
      "reading csv : high_diamond_ranked_10min.csv2.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.11321568489074707 seconds\n",
      "\n",
      "You have no test dataset !\n",
      "\n",
      "> Number of common features : 39\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 0\n",
      "> Number of numerical features: 39\n",
      "> Number of training samples : 9879\n",
      "> Number of test samples : 0\n",
      "\n",
      "> You have no missing values on train set...\n",
      "\n",
      "> Task : classification\n",
      "0.0    4949\n",
      "1.0    4930\n",
      "Name: blueWins, dtype: int64\n",
      "\n",
      "encoding target ...\n",
      "\n",
      "You have no test dataset...\n",
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tttra\\Anaconda3\\envs\\tenserflow\\lib\\site-packages\\mlbox\\optimisation\\optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.7162668286263791\n",
      "VARIANCE : 0.008467866131537325 (fold 1 = 0.7139386577588824, fold 2 = 0.7072578196173702, fold 3 = 0.7276040085028849)\n",
      "CPU time: 3.362366199493408 seconds\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.22889813189704142}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7184937746735499                                                                             \n",
      "VARIANCE : 0.0048270549721900445 (fold 1 = 0.7163680534467052, fold 2 = 0.7139386577588824, fold 3 = 0.7251746128150622)\n",
      "CPU time: 23.649430751800537 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18690036000546453}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7169754023686608                                                                             \n",
      "VARIANCE : 0.0059559431858915365 (fold 1 = 0.711205587610082, fold 2 = 0.7145460066808381, fold 3 = 0.7251746128150622)\n",
      "CPU time: 4.940669775009155 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.22296211021334347}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7150521307824679                                                                             \n",
      "VARIANCE : 0.0015746886512910583 (fold 1 = 0.7139386577588824, fold 2 = 0.7139386577588824, fold 3 = 0.7172790768296387)\n",
      "CPU time: 6.195988893508911 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.06065700544075759}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7224415426662617                                                                             \n",
      "VARIANCE : 0.005224612977250314 (fold 1 = 0.7230488915882174, fold 2 = 0.7157607045247495, fold 3 = 0.7285150318858185)\n",
      "CPU time: 3.3002827167510986 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.17877643420855344}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7174815264702906                                                                             \n",
      "VARIANCE : 0.005655922682335873 (fold 1 = 0.7133313088369269, fold 2 = 0.7136349832979046, fold 3 = 0.7254782872760401)\n",
      "CPU time: 4.371659278869629 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.15199425565644234}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7205182710800688                                                                             \n",
      "VARIANCE : 0.0033296657968212365 (fold 1 = 0.7187974491345278, fold 2 = 0.7175827512906164, fold 3 = 0.7251746128150622)\n",
      "CPU time: 3.96382474899292 seconds                                                                                     \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.15859588386188578}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7152545804231197                                                                             \n",
      "VARIANCE : 0.0059421642358292 (fold 1 = 0.7109019131491041, fold 2 = 0.711205587610082, fold 3 = 0.7236562405101731)   \n",
      "CPU time: 4.336701393127441 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.25075497701350236}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7210243951816985                                                                             \n",
      "VARIANCE : 0.007526118147764393 (fold 1 = 0.7194047980564835, fold 2 = 0.7127239599149712, fold 3 = 0.7309444275736411)\n",
      "CPU time: 3.058194160461426 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1820883913980068}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7210243951816987                                                                             \n",
      "VARIANCE : 0.0021663057555453796 (fold 1 = 0.720315821439417, fold 2 = 0.7187974491345278, fold 3 = 0.723959914971151) \n",
      "CPU time: 3.8690431118011475 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.10807711619848649}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7138374329385565                                                                             \n",
      "VARIANCE : 0.007373448264591278 (fold 1 = 0.7084725174612815, fold 2 = 0.7087761919222594, fold 3 = 0.7242635894321288)\n",
      "CPU time: 4.388615608215332 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2535638841295322}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7173803016499646                                                                             \n",
      "VARIANCE : 0.00400829838510444 (fold 1 = 0.7121166109930155, fold 2 = 0.7181901002125721, fold 3 = 0.7218341937443061) \n",
      "CPU time: 3.4472317695617676 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.12734054464579284}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7150521307824679                                                                             \n",
      "VARIANCE : 0.004451590935782188 (fold 1 = 0.713027634375949, fold 2 = 0.7109019131491041, fold 3 = 0.7212268448223504) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 3.9055869579315186 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.14278606264224958}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7205182710800688                                                                             \n",
      "VARIANCE : 0.0033296657968212365 (fold 1 = 0.7187974491345278, fold 2 = 0.7175827512906164, fold 3 = 0.7251746128150622)\n",
      "CPU time: 4.075855731964111 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.1170729117016954}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7146472315011639                                                                             \n",
      "VARIANCE : 0.0033846044128556622 (fold 1 = 0.7109019131491041, fold 2 = 0.7139386577588824, fold 3 = 0.7191011235955056)\n",
      "CPU time: 3.722651243209839 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2889596351924472}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7172790768296385                                                                             \n",
      "VARIANCE : 0.004711034022965944 (fold 1 = 0.7187974491345278, fold 2 = 0.7109019131491041, fold 3 = 0.7221378682052839)\n",
      "CPU time: 4.433169603347778 seconds                                                                                    \n",
      "100%|███████████████████████████████████████████████| 15/15 [01:22<00:00,  5.48s/trial, best loss: -0.7224415426662617]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'random_projection', 'est__max_depth': 3, 'fs__threshold': 0.06065700544075759, 'ne__numerical_strategy': 0}\n",
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tttra\\Anaconda3\\envs\\tenserflow\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 1.6390135288238525 seconds\n"
     ]
    }
   ],
   "source": [
    "#Classification\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "import csv \n",
    "\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"../Data/titanic/train.csv\",\"../Data/titanic/test.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"Survived\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "# Declare an optimiser. Scoring possibilities for classification lie in :\n",
    "# {\"accuracy\", \"roc_auc\", \"f1\", \"neg_log_loss\", \"precision\", \"recall\"}\n",
    "opt = Optimiser(scoring='accuracy', n_folds=3)\n",
    "opt.evaluate(None, data)\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {'ne__numerical_strategy': {\"search\": \"choice\", \"space\": [0]},\n",
    "         'ce__strategy': {\"search\": \"choice\",\n",
    "                          \"space\": [\"label_encoding\",\n",
    "                                    \"random_projection\",\n",
    "                                    \"entity_embedding\"]},\n",
    "         'fs__threshold': {\"search\": \"uniform\",\n",
    "                           \"space\": [0.01, 0.3]},\n",
    "         'est__max_depth': {\"search\": \"choice\",\n",
    "                            \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "         }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "\n",
    "# Make prediction and save the results in save folder.\n",
    "prd = Predictor()\n",
    "prd.fit_predict(best, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.6609208583831787 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.5561227798461914 seconds\n",
      "\n",
      "> Number of common features : 80\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 43\n",
      "> Number of numerical features: 37\n",
      "> Number of training samples : 1460\n",
      "> Number of test samples : 1459\n",
      "\n",
      "> Top sparse features (% missing values on train set):\n",
      "PoolQC         99.5\n",
      "MiscFeature    96.3\n",
      "Alley          93.8\n",
      "Fence          80.8\n",
      "FireplaceQu    47.3\n",
      "dtype: float64\n",
      "\n",
      "> Task : regression\n",
      "count      1460.000000\n",
      "mean     180921.195890\n",
      "std       79442.502883\n",
      "min       34900.000000\n",
      "25%      129975.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n",
      "\n",
      "computing drifts ...\n",
      "CPU time: 4.514478921890259 seconds\n",
      "\n",
      "> Top 10 drifts\n",
      "\n",
      "('Id', 0.9986301369863013)\n",
      "('TotalBsmtSF', 0.043363777307745766)\n",
      "('TotRmsAbvGrd', 0.04232541177360938)\n",
      "('GarageCars', 0.038302942128133566)\n",
      "('BsmtFinSF1', 0.03555577306767521)\n",
      "('MasVnrArea', 0.03534951366091965)\n",
      "('FireplaceQu', 0.0350615121699962)\n",
      "('BsmtFinType2', 0.0316924798209246)\n",
      "('Exterior2nd', 0.03045336604509674)\n",
      "('Neighborhood', 0.03010829529445358)\n",
      "\n",
      "> Deleted variables : ['Id']\n",
      "> Drift coefficients dumped into directory : save\n",
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.724280495125964\n",
      "VARIANCE : 0.8209723498000103 (fold 1 = -10.46930111453782, fold 2 = -10.122939172213853, fold 3 = -8.580601198626216)\n",
      "CPU time: 10.2386474609375 seconds\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}     \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.05172919388966048}\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.16678475900378\n",
      "VARIANCE : 0.8417502919612839 (fold 1 = -10.04577078627961, fold 2 = -9.42252767935932, fold 3 = -8.03205581137241)\n",
      "CPU time: 4.288841009140015 seconds                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2505993630769116}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "  7%|▋         | 1/15 [00:04<01:00,  4.36s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.776082866600623\n",
      "VARIANCE : 0.7516477608352751 (fold 1 = -10.47311964228327, fold 2 = -10.122594215218452, fold 3 = -8.732534742300148)\n",
      "CPU time: 4.583108186721802 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                              \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.23337067946461196}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 13%|█▎        | 2/15 [00:09<00:57,  4.43s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471898061576.9529, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325557539683.7268, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 438212605577.8767, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.291406026526055\n",
      "VARIANCE : 0.7083677015222534 (fold 1 = -9.819690877823804, fold 2 = -9.764395568544344, fold 3 = -8.290131633210015)\n",
      "CPU time: 11.250384330749512 seconds                                          \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.08964778899592642}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 20%|██        | 3/15 [00:20<01:17,  6.49s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.52563752483587\n",
      "VARIANCE : 0.7807159274768404 (fold 1 = -10.049406840477472, fold 2 = -10.105492326181789, fold 3 = -8.42201340784835)\n",
      "CPU time: 5.466446161270142 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.14349204460034615}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 27%|██▋       | 4/15 [00:25<01:08,  6.19s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.618391243024625\n",
      "VARIANCE : 0.8095396182204544 (fold 1 = -10.268823623461811, fold 2 = -10.109100833169597, fold 3 = -8.477249272442469)\n",
      "CPU time: 7.311812162399292 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.20292900230097088}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 33%|███▎      | 5/15 [00:33<01:05,  6.53s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.900488804722508\n",
      "VARIANCE : 0.7775651375657084 (fold 1 = -10.486579256087197, fold 2 = -10.413225684730481, fold 3 = -8.801661473349847)\n",
      "CPU time: 4.468336343765259 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.21069630821156415}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 40%|████      | 6/15 [00:37<00:53,  5.92s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.636978624867487\n",
      "VARIANCE : 0.7768116198081974 (fold 1 = -10.398918206131897, fold 2 = -9.941385004583006, fold 3 = -8.570632663887556)\n",
      "CPU time: 4.361413240432739 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.031485025338856554}   \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 47%|████▋     | 7/15 [00:42<00:43,  5.46s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.4660029699925\n",
      "VARIANCE : 0.7066664330333843 (fold 1 = -10.074897278352553, fold 2 = -9.847851642915652, fold 3 = -8.475259988709292)\n",
      "CPU time: 4.726389408111572 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2918933925041057}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 53%|█████▎    | 8/15 [00:46<00:36,  5.25s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.937416594497549\n",
      "VARIANCE : 0.5684315713303486 (fold 1 = -10.578637795708385, fold 2 = -10.036684792196992, fold 3 = -9.196927195587271)\n",
      "CPU time: 6.10563063621521 seconds                                            \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}   \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                             \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18543968823843288}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 60%|██████    | 9/15 [00:52<00:33,  5.51s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 353915657654.1744, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 212966893949.87384, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 293134499318.21173, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.667853269039943\n",
      "VARIANCE : 0.9530074670860331 (fold 1 = -10.357424386818751, fold 2 = -10.325915457132387, fold 3 = -8.320219963168691)\n",
      "CPU time: 7.382337331771851 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.05912640920756293}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 67%|██████▋   | 10/15 [01:00<00:30,  6.09s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.35323422801509\n",
      "VARIANCE : 0.8512341584675703 (fold 1 = -10.261450323408946, fold 2 = -9.583419269471955, fold 3 = -8.214833091164367)\n",
      "CPU time: 3.946617603302002 seconds                                            \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.17679926090749812}     \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 73%|███████▎  | 11/15 [01:04<00:21,  5.45s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.552104951482155\n",
      "VARIANCE : 0.7620571993226769 (fold 1 = -10.324820807651003, fold 2 = -9.816346298511231, fold 3 = -8.515147748284226)\n",
      "CPU time: 4.32455039024353 seconds                                             \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                               \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2892114931488397}      \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 80%|████████  | 12/15 [01:08<00:15,  5.13s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471898061576.9529, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325557539683.7268, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 438212605577.8767, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.250951463299302\n",
      "VARIANCE : 0.6990484697913713 (fold 1 = -9.76886851767626, fold 2 = -9.721255980742596, fold 3 = -8.262729891479045)\n",
      "CPU time: 9.8928701877594 seconds                                              \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                               \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.045470207038264356}    \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 87%|████████▋ | 13/15 [01:18<00:13,  6.57s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471898061576.9529, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 325557539683.7268, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 438212605577.8767, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.356842165606485\n",
      "VARIANCE : 0.7687203093975364 (fold 1 = -9.924057662762314, fold 2 = -9.87641329247293, fold 3 = -8.270055541584211)\n",
      "CPU time: 10.259782314300537 seconds                                           \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}    \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                 \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2567090768846798}      \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      " 93%|█████████▎| 14/15 [01:28<00:07,  7.69s/trial, best loss: 9.16678475900378]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 382002478923.82025, tolerance: 577337156.9466883\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226417788333.6526, tolerance: 630960719.5801489\n",
      "  positive)\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326095800875.1044, tolerance: 633252671.051735\n",
      "  positive)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SCORE : make_scorer(<lambda>, greater_is_better=False) = -9.926518770381298\n",
      "VARIANCE : 0.6215658598602214 (fold 1 = -10.519801832360304, fold 2 = -10.191595659503042, fold 3 = -9.068158819280548)\n",
      "CPU time: 4.732445001602173 seconds                                            \n",
      "100%|██████████| 15/15 [01:33<00:00,  6.25s/trial, best loss: 9.16678475900378]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'random_projection', 'est__max_depth': 3, 'fs__threshold': 0.05172919388966048, 'ne__numerical_strategy': 0}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2af8d53c596c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# selection strategy and one estimator strategy at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oui : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mlbox/optimisation/optimiser.py\u001b[0m in \u001b[0;36moptimise\u001b[0;34m(self, space, df, max_evals)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mhyper_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"space\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "#Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from math import sqrt\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import make_scorer\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"../Data/California_house/train.csv\", \"../Data/California_house/test.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"SalePrice\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "mape = make_scorer(lambda y_true,\n",
    "                   y_pred: 100*np.sum(\n",
    "                                      np.abs(y_true-y_pred)/y_true\n",
    "                                      )/len(y_true),\n",
    "                   greater_is_better=False,\n",
    "                   needs_proba=False)\n",
    "# Declare an optimiser. You can declare your own score\n",
    "# as presented here or use one in\n",
    "# {\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"neg_mean_squared_log_error\", \"neg_median_absolute_error\",\"r2\"}\n",
    "opt = Optimiser(scoring=\"mean_squared_error\", n_folds=3)\n",
    "print(\"OUIIII\" ,opt.evaluate(None, data))\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {\n",
    "        'ne__numerical_strategy': {\"search\": \"choice\",\n",
    "                                   \"space\": [0]},\n",
    "        'ce__strategy': {\"search\": \"choice\",\n",
    "                         \"space\": [\"label_encoding\",\n",
    "                                   \"random_projection\",\n",
    "                                   \"entity_embedding\"]},\n",
    "        'fs__threshold': {\"search\": \"uniform\",\n",
    "                          \"space\": [0.01, 0.3]},\n",
    "        'est__max_depth': {\"search\": \"choice\",\n",
    "                           \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "        }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "print(\"oui : \",opt.optimisation.Optimiser(\"mean_squared_error\").optimise(space, data, 15)))\n",
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n",
      "/opt/conda/lib/python3.7/site-packages/mlbox/optimisation/optimiser.py:296: UserWarning: Unknown or invalid scoring metric. neg_mean_squared_error is used instead.\n",
      "  warnings.warn(\"Unknown or invalid scoring metric. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n",
      "\n",
      "MEAN SCORE : neg_mean_squared_error = -978096668.7284681\n",
      "VARIANCE : 363401763.5154683 (fold 1 = -819178020.6825377, fold 2 = -1480817035.214201, fold 3 = -634294950.2886657)\n",
      "CPU time: 9.591639280319214 seconds\n",
      "\n",
      "OUIIII -978096668.7284681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31274.53705492697"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Optimiser(scoring=\"mean_squared_error\", n_folds=3)\n",
    "print(\"OUIIII\" ,opt.evaluate(None, data))\n",
    "sqrt(978096668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.5330097675323486 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.5509545803070068 seconds\n",
      "\n",
      "> Number of common features : 80\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 43\n",
      "> Number of numerical features: 37\n",
      "> Number of training samples : 1460\n",
      "> Number of test samples : 1459\n",
      "\n",
      "> Top sparse features (% missing values on train set):\n",
      "PoolQC         99.5\n",
      "MiscFeature    96.3\n",
      "Alley          93.8\n",
      "Fence          80.8\n",
      "FireplaceQu    47.3\n",
      "dtype: float64\n",
      "\n",
      "> Task : regression\n",
      "count      1460.000000\n",
      "mean     180921.195890\n",
      "std       79442.502883\n",
      "min       34900.000000\n",
      "25%      129975.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n",
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py:315: UserWarning: Persisting input arguments took 0.78s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py:315: UserWarning: Persisting input arguments took 0.87s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 646789911208.9197, tolerance: 920791133.4609977\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 35.263222217559814 seconds\n",
      "\n",
      "> Feature importances dumped into directory : save\n",
      "\n",
      "predicting...\n",
      "CPU time: 0.9136080741882324 seconds\n",
      "\n",
      "> Overview on predictions : \n",
      "\n",
      "   SalePrice_predicted\n",
      "0        123846.655010\n",
      "1        163911.554538\n",
      "2        186024.245125\n",
      "3        189191.083244\n",
      "4        188858.664274\n",
      "5        178767.105389\n",
      "6        169939.227833\n",
      "7        164569.258979\n",
      "8        183016.955618\n",
      "9        126221.026997\n",
      "\n",
      "dumping predictions into directory : save ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'mlbox.prediction.predictor.Predictor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45f4a4f8eef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'mlbox.prediction.predictor.Predictor'>"
     ]
    }
   ],
   "source": [
    "california_data = pd.read_csv(\"../Data/California_house/train.csv\")\n",
    "X = rd.train_test_split(paths, target_name)\n",
    "y = california_data.SalePrice\n",
    "# Make prediction and save the results in save folder.\n",
    "prd = Predictor()\n",
    "prd = prd.fit_predict(best, X)\n",
    "sqrt(sklearn.metrics.mean_squared_error(y, prd.SalePrice_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Predictor' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e579909d5fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SalePrice_predicted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Predictor' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "sqrt(sklearn.metrics.mean_squared_error(data, prd[\"SalePrice_predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from math import sqrt\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import make_scorer\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"../Data/avocado_prices/avocado.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"AveragePrice\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "mape = make_scorer(lambda y_true,\n",
    "                   y_pred: 100*np.sum(\n",
    "                                      np.abs(y_true-y_pred)/y_true\n",
    "                                      )/len(y_true),\n",
    "                   greater_is_better=False,\n",
    "                   needs_proba=False)\n",
    "# Declare an optimiser. You can declare your own score\n",
    "# as presented here or use one in\n",
    "# {\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"neg_mean_squared_log_error\", \"neg_median_absolute_error\",\"r2\"}\n",
    "opt = Optimiser(scoring=\"mean_squared_error\", n_folds=3)\n",
    "print(\"OUIIII\" ,opt.evaluate(None, data))\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {\n",
    "        'ne__numerical_strategy': {\"search\": \"choice\",\n",
    "                                   \"space\": [0]},\n",
    "        'ce__strategy': {\"search\": \"choice\",\n",
    "                         \"space\": [\"label_encoding\",\n",
    "                                   \"random_projection\",\n",
    "                                   \"entity_embedding\"]},\n",
    "        'fs__threshold': {\"search\": \"uniform\",\n",
    "                          \"space\": [0.01, 0.3]},\n",
    "        'est__max_depth': {\"search\": \"choice\",\n",
    "                           \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "        }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = Optimiser(scoring=\"mean_squared_error\", n_folds=3)\n",
    "print(\"OUIIII\" ,opt.evaluate(None, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil = \"Data/lol/high_diamond_ranked_10min.csv\"\n",
    "csvfilename = open(fil, 'r').readlines()\n",
    "#store header values\n",
    "header = csvfilename[0] \n",
    "#remove header from list\n",
    "csvfilename.pop(0) \n",
    "file = 1\n",
    "#Number of lines to be written in new file\n",
    "record_per_file = 8000\n",
    "\n",
    "for j in range(len(csvfilename)):\n",
    "    if j % record_per_file == 0:\n",
    "        write_file = csvfilename[j:j+record_per_file]\n",
    "                #adding header at the start of the write_file\n",
    "        write_file.insert(0, header)\n",
    "        #write in file\n",
    "        open(str(fil)+ str(file) + '.csv', 'w+').writelines(write_file)\n",
    "        file+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
