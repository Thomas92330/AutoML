{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading csv : train.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.2824747562408447 seconds\n",
      "\n",
      "reading csv : test.csv ...\n",
      "cleaning data ...\n",
      "CPU time: 0.0659022331237793 seconds\n",
      "\n",
      "> Number of common features : 11\n",
      "\n",
      "gathering and crunching for train and test datasets ...\n",
      "reindexing for train and test datasets ...\n",
      "dropping training duplicates ...\n",
      "dropping constant variables on training set ...\n",
      "\n",
      "> Number of categorical features: 5\n",
      "> Number of numerical features: 6\n",
      "> Number of training samples : 891\n",
      "> Number of test samples : 418\n",
      "\n",
      "> Top sparse features (% missing values on train set):\n",
      "Cabin       77.1\n",
      "Age         19.9\n",
      "Embarked     0.2\n",
      "dtype: float64\n",
      "\n",
      "> Task : classification\n",
      "0.0    549\n",
      "1.0    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "encoding target ...\n",
      "\n",
      "computing drifts ...\n",
      "CPU time: 0.3208177089691162 seconds\n",
      "\n",
      "> Top 10 drifts\n",
      "\n",
      "('PassengerId', 1.0)\n",
      "('Name', 0.9895998527491288)\n",
      "('Ticket', 0.677220232385404)\n",
      "('Cabin', 0.19771080102497018)\n",
      "('Embarked', 0.07508027318074184)\n",
      "('Age', 0.058879254044637896)\n",
      "('Parch', 0.0425812971625279)\n",
      "('SibSp', 0.04178539993630692)\n",
      "('Fare', 0.033030096506215134)\n",
      "('Sex', 0.01123045846177817)\n",
      "\n",
      "> Deleted variables : ['Name', 'PassengerId', 'Ticket']\n",
      "> Drift coefficients dumped into directory : save\n",
      "No parameters set. Default configuration is tested\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      "\n",
      ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
      "\n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
      "\n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tttra\\Anaconda3\\envs\\tenserflow\\lib\\site-packages\\mlbox\\optimisation\\optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
      "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN SCORE : accuracy = 0.8103254769921436\n",
      "VARIANCE : 0.03534908136481175 (fold 1 = 0.7609427609427609, fold 2 = 0.8282828282828283, fold 3 = 0.8417508417508418)\n",
      "CPU time: 0.998481273651123 seconds\n",
      "\n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2022316867360934}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7991021324354657                                                                             \n",
      "VARIANCE : 0.027537248364501242 (fold 1 = 0.7609427609427609, fold 2 = 0.8114478114478114, fold 3 = 0.8249158249158249)\n",
      "CPU time: 12.336735248565674 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.19427794698663323}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8249158249158249                                                                             \n",
      "VARIANCE : 0.03509875593964507 (fold 1 = 0.7777777777777778, fold 2 = 0.835016835016835, fold 3 = 0.8619528619528619)  \n",
      "CPU time: 1.808077335357666 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.15664534331020952}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.819304152637486                                                                              \n",
      "VARIANCE : 0.016797564025921197 (fold 1 = 0.8013468013468014, fold 2 = 0.8148148148148148, fold 3 = 0.8417508417508418)\n",
      "CPU time: 0.8856470584869385 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.24164417822890114}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8215488215488215                                                                             \n",
      "VARIANCE : 0.019244027159912736 (fold 1 = 0.797979797979798, fold 2 = 0.8215488215488216, fold 3 = 0.8451178451178452) \n",
      "CPU time: 0.8417637348175049 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.11706459502418497}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7991021324354657                                                                             \n",
      "VARIANCE : 0.027537248364501242 (fold 1 = 0.7609427609427609, fold 2 = 0.8114478114478114, fold 3 = 0.8249158249158249)\n",
      "CPU time: 0.8523738384246826 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.23403082993207547}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8159371492704826                                                                             \n",
      "VARIANCE : 0.019504093374840378 (fold 1 = 0.7946127946127947, fold 2 = 0.8114478114478114, fold 3 = 0.8417508417508418)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.9969990253448486 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.08910319063584117}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8249158249158249                                                                             \n",
      "VARIANCE : 0.03509875593964507 (fold 1 = 0.7777777777777778, fold 2 = 0.835016835016835, fold 3 = 0.8619528619528619)  \n",
      "CPU time: 0.688654899597168 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.08316379990219651}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8148148148148149                                                                             \n",
      "VARIANCE : 0.03241196201614736 (fold 1 = 0.7710437710437711, fold 2 = 0.8249158249158249, fold 3 = 0.8484848484848485) \n",
      "CPU time: 0.6586563587188721 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.16123948585428835}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8013468013468014                                                                             \n",
      "VARIANCE : 0.02380830913086024 (fold 1 = 0.7676767676767676, fold 2 = 0.8181818181818182, fold 3 = 0.8181818181818182) \n",
      "CPU time: 0.8052594661712646 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'random_projection'}                                                                      \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.11317568465549095}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 7, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8159371492704826                                                                             \n",
      "VARIANCE : 0.019504093374840378 (fold 1 = 0.7946127946127947, fold 2 = 0.8114478114478114, fold 3 = 0.8417508417508418)\n",
      "CPU time: 0.8840012550354004 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.029372293928702754}                                            \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8013468013468014                                                                             \n",
      "VARIANCE : 0.02380830913086024 (fold 1 = 0.7676767676767676, fold 2 = 0.8181818181818182, fold 3 = 0.8181818181818182) \n",
      "CPU time: 0.7711920738220215 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.10715191637136241}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 6, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.7991021324354658                                                                             \n",
      "VARIANCE : 0.02712243765116628 (fold 1 = 0.7609427609427609, fold 2 = 0.8215488215488216, fold 3 = 0.8148148148148148) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.756927490234375 seconds                                                                                    \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'entity_embedding'}                                                                       \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.16110942837672357}                                             \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8013468013468014                                                                             \n",
      "VARIANCE : 0.02380830913086024 (fold 1 = 0.7676767676767676, fold 2 = 0.8181818181818182, fold 3 = 0.8181818181818182) \n",
      "CPU time: 1.0138192176818848 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2692880483744912}                                              \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8226711560044894                                                                             \n",
      "VARIANCE : 0.03209955027177348 (fold 1 = 0.7878787878787878, fold 2 = 0.8148148148148148, fold 3 = 0.8653198653198653) \n",
      "CPU time: 0.6555986404418945 seconds                                                                                   \n",
      "##################################################### testing hyper-parameters... #####################################################\n",
      ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}                                            \n",
      ">>> CA ENCODER :{'strategy': 'label_encoding'}                                                                         \n",
      ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.017869171107749403}                                            \n",
      ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
      "MEAN SCORE : accuracy = 0.8148148148148149                                                                             \n",
      "VARIANCE : 0.026225188429961684 (fold 1 = 0.7845117845117845, fold 2 = 0.8114478114478114, fold 3 = 0.8484848484848485)\n",
      "CPU time: 0.5277624130249023 seconds                                                                                   \n",
      "100%|███████████████████████████████████████████████| 15/15 [00:24<00:00,  1.65s/trial, best loss: -0.8249158249158249]\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "{'ce__strategy': 'label_encoding', 'est__max_depth': 7, 'fs__threshold': 0.19427794698663323, 'ne__numerical_strategy': 0}\n",
      "\n",
      "fitting the pipeline ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tttra\\Anaconda3\\envs\\tenserflow\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.37947726249694824 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"A classification example using mlbox.\"\"\"\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"Data/titanic/train.csv\", 'Data/titanic/test.csv']\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"Survived\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "# Declare an optimiser. Scoring possibilities for classification lie in :\n",
    "# {\"accuracy\", \"roc_auc\", \"f1\", \"neg_log_loss\", \"precision\", \"recall\"}\n",
    "opt = Optimiser(scoring='accuracy', n_folds=3)\n",
    "opt.evaluate(None, data)\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {'ne__numerical_strategy': {\"search\": \"choice\", \"space\": [0]},\n",
    "         'ce__strategy': {\"search\": \"choice\",\n",
    "                          \"space\": [\"label_encoding\",\n",
    "                                    \"random_projection\",\n",
    "                                    \"entity_embedding\"]},\n",
    "         'fs__threshold': {\"search\": \"uniform\",\n",
    "                           \"space\": [0.01, 0.3]},\n",
    "         'est__max_depth': {\"search\": \"choice\",\n",
    "                            \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "         }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "\n",
    "# Make prediction and save the results in save folder.\n",
    "prd = Predictor()\n",
    "prd.fit_predict(best, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A regression example using mlbox.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from mlbox.preprocessing import Reader\n",
    "from mlbox.preprocessing import Drift_thresholder\n",
    "from mlbox.optimisation import make_scorer\n",
    "from mlbox.optimisation import Optimiser\n",
    "from mlbox.prediction import Predictor\n",
    "\n",
    "# Paths to the train set and the test set.\n",
    "paths = [\"Data/California_house/train.csv\", \"Data/California_house/test.csv\"]\n",
    "# Name of the feature to predict.\n",
    "# This columns should only be present in the train set.\n",
    "target_name = \"SalePrice\"\n",
    "\n",
    "# Reading and cleaning all files\n",
    "# Declare a reader for csv files\n",
    "rd = Reader(sep=',')\n",
    "# Return a dictionnary containing three entries\n",
    "# dict[\"train\"] contains training samples withtout target columns\n",
    "# dict[\"test\"] contains testing elements withtout target columns\n",
    "# dict[\"target\"] contains target columns for training samples.\n",
    "data = rd.train_test_split(paths, target_name)\n",
    "\n",
    "dft = Drift_thresholder()\n",
    "data = dft.fit_transform(data)\n",
    "\n",
    "# Tuning\n",
    "mape = make_scorer(lambda y_true,\n",
    "                   y_pred: 100*np.sum(\n",
    "                                      np.abs(y_true-y_pred)/y_true\n",
    "                                      )/len(y_true),\n",
    "                   greater_is_better=False,\n",
    "                   needs_proba=False)\n",
    "# Declare an optimiser. You can declare your own score\n",
    "# as presented here or use one in\n",
    "# {\"neg_mean_absolute_error\", \"neg_mean_squared_error\", \"neg_mean_squared_log_error\", \"neg_median_absolute_error\",\"r2\"}\n",
    "opt = Optimiser(scoring=mape, n_folds=3)\n",
    "opt.evaluate(None, data)\n",
    "\n",
    "# Space of hyperparameters\n",
    "# The keys must respect the following syntax : \"enc__param\".\n",
    "#   \"enc\" = \"ne\" for na encoder\n",
    "#   \"enc\" = \"ce\" for categorical encoder\n",
    "#   \"enc\" = \"fs\" for feature selector [OPTIONAL]\n",
    "#   \"enc\" = \"stck\"+str(i) to add layer n°i of meta-features [OPTIONAL]\n",
    "#   \"enc\" = \"est\" for the final estimator\n",
    "#   \"param\" : a correct associated parameter for each step.\n",
    "#   Ex: \"max_depth\" for \"enc\"=\"est\", ...\n",
    "# The values must respect the syntax: {\"search\":strategy,\"space\":list}\n",
    "#   \"strategy\" = \"choice\" or \"uniform\". Default = \"choice\"\n",
    "#   list : a list of values to be tested if strategy=\"choice\".\n",
    "#   Else, list = [value_min, value_max].\n",
    "# Available strategies for ne_numerical_strategy are either an integer, a float\n",
    "#   or in {'mean', 'median', \"most_frequent\"}\n",
    "# Available strategies for ce_strategy are:\n",
    "#   {\"label_encoding\", \"dummification\", \"random_projection\", entity_embedding\"}\n",
    "space = {\n",
    "        'ne__numerical_strategy': {\"search\": \"choice\",\n",
    "                                   \"space\": [0]},\n",
    "        'ce__strategy': {\"search\": \"choice\",\n",
    "                         \"space\": [\"label_encoding\",\n",
    "                                   \"random_projection\",\n",
    "                                   \"entity_embedding\"]},\n",
    "        'fs__threshold': {\"search\": \"uniform\",\n",
    "                          \"space\": [0.01, 0.3]},\n",
    "        'est__max_depth': {\"search\": \"choice\",\n",
    "                           \"space\": [3, 4, 5, 6, 7]}\n",
    "\n",
    "        }\n",
    "\n",
    "# Optimises hyper-parameters of the whole Pipeline with a given scoring\n",
    "# function. Algorithm used to optimize : Tree Parzen Estimator.\n",
    "#\n",
    "# IMPORTANT : Try to avoid dependent parameters and to set one feature\n",
    "# selection strategy and one estimator strategy at a time.\n",
    "best = opt.optimise(space, data, 15)\n",
    "\n",
    "# Make prediction and save the results in save folder.\n",
    "prd = Predictor()\n",
    "prd.fit_predict(best, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
